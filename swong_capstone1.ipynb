{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone 1: Pneumonia X Ray Image Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Springboard--Data Science Career Track\n",
    "Ideas for Capstone Project 1\n",
    "By Andy Wong\n",
    "May 2020\n",
    "\n",
    "\n",
    "ML/DL model: using models to detect X-ray images for Pneumonia. This would be a supervised learning model, where the model either predicts correctly a 1(true) for pneumonia or a 0(false), no pneumonia. Datasets can be found in kaggle or some other public medical database. Data would need to be cleaned, filtered and organized, and then given to our model. Other challenges include, how to train the model, what model to use, and what python libraries to import for this project. \n",
    "\thttps://www.linkedin.com/pulse/detecting-pneumonia-deep-learning-soft-introduction-neural-erthal/\n",
    "\n",
    "\tDatasets:\n",
    "\thttps://www.kaggle.com/paultimothymooney/chest-xray-pneumonia\n",
    "\tData.world\n",
    "\t\t*\tcreated this account for extra dataset for pneumonia project\n",
    "\n",
    "\t\n",
    "Computer Vision\n",
    "Convolutional Neural Networks\n",
    "Dataframes to differentiate each individual imagine either they are with pneumonia(1) or normal(0)\n",
    "Problems to look out for: imbalance amount of pictures between the Pneumonia pics vs. Normal pics\n",
    "\n",
    "Library to use: Keras\n",
    "\n",
    "Found Dataset for Pneumonia from Stanford’s  chest X-rays database.  I’m still not sure how to extract the dataset yet, which I will need to dig into it later\n",
    "https://stanfordmlgroup.github.io/competitions/chexpert/\n",
    "\n",
    "Radiological Society of North America (RSNA)\n",
    "https://www.rsna.org/en/education/ai-resources-and-training/ai-image-challenge/RSNA-Pneumonia-Detection-Challenge-2018\n",
    "\n",
    "\n",
    "ML/DL model: using models to identify people and or facial expressions ( facial recognition ). Datasets with labels and photographs could be provided to train the model. Other challenges include, how to best train the model, what model to use, and what python libraries to import for this project. In addition, this could be used to recognize familiar faces and also better understand what people might be feeling. \n",
    "\n",
    "ML/DL model: models to detect street signs and objects(i.e. Cars, trucks, traffic lights), through some kind of classification method (Bayes classifier). This would be useful for self driving projects like autonomous vehicles. Being able to distinguish traffic signs and other things on the road could have useful applications for future projects using things like computer vision. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "decided to use dataset from Kaggle as follow link: \t\n",
    "Datasets:\n",
    "\thttps://www.kaggle.com/paultimothymooney/chest-xray-pneumonia\n",
    "    \n",
    "    Data Wrangling: filtering, cleaning, reorganizing data.\n",
    "    \n",
    "    image data are different than most text data, which it comes in different sizes(pixel sizes)\n",
    "    In my case: 1857 X 1317, 2111 X 1509, 2031 X 1837, 1663 X 1327, etc\n",
    "    It will need to normalize all pictures for machine learning model to be one single vector space comparison from two-dimensional matrix, and define the Design Matrix, and all Labels(Normal, Pneumonia Bacterial, Pneumonia Viral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Step1: How to convert all pictures as same aspect ratio (600X400) (initially 1 then 5, then 10, etc)\n",
    "Step2: How to load in many pictures at the same time: for loop?\n",
    "Step3: comparing 2D image into 1D\n",
    "    array.ravel() or .flatten()\n",
    "Step4: Comparing pixels to pixels\n",
    "Step5: Apply Logistic Regression --> Define Design matrix, labels --> Classification problem\n",
    "Step6: Dealing with imbalance dataset(Normal Lung(more), Pneumonia(less))\n",
    "Step7: How do you subdivide the Pneumonia Viral vs. Bacterial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step1: Resizing all Pictures into nXm = 800 X 400 pixels.  For some reason, n is the columns, and m is the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'image' from 'PIL' (C:\\Users\\sanch\\Anaconda3\\lib\\site-packages\\PIL\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-7892611e7a30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'image' from 'PIL' (C:\\Users\\sanch\\Anaconda3\\lib\\site-packages\\PIL\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from PIL import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AJ's Notes\n",
    "\n",
    "https://datascience.stackexchange.com/questions/1213/machine-learning-algorithms-for-2d-data\n",
    "You can simply convert a MxN matrix (your image) into a MN dimensional vector. For instance if you have 10 images each of which 10x10 pixels, you can convert them to 10 vectors each of them containing 100 element (you can do it row-wise or column-wise, does not matter). Then putting all these vectors on each other constructs a nxd matrix where n is the number of images and d is the number of pixels in each image.\n",
    "\n",
    "So far we just prepared data for analysis. Now let's go to the question:\n",
    "\n",
    "I'm looking for a supervised learning algorithm that can take 2d data for input and output.\n",
    "What does that mean?\n",
    "\n",
    "First- The dimension of input-output is not a property of a machine learning algorithm.\n",
    "\n",
    "Second- By 2d, you mean a matrix? I'm afraid your data is not really 2d! If you mean a matrix, a MxN matrix is a data of M samples in N dimensional space. also those vectors you may produce from your images are in MN dimensional space.\n",
    "\n",
    "Third- A supervised algorithm takes some teaching samples (called training) to learn a task. What are those teachers here? If you have a training data which contains some blurred and corresponding original images then you can try to learn the place of white pixels by exploring blurred area. My suggestion:\n",
    "\n",
    "If a smoothing filter has been applied to your image, the blurred pixels most probably look like a gaussian. So first extract the gaussians.\n",
    "As you already have the place of sharp whites correspond to those gaussians you can use the mean, location of the mean and also variance as features (inputs) and the place of sharp white pixels as the target (output).\n",
    "The classifier could be a simple neural network (a MLP should work here) or a simple SVM.\n",
    "\n",
    "The answer above can not be evaluated without more information about your data and a more specific description of the question (e.g. What are your images exactly? if you can post one of them here I can probably help more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converted all unstructured image data within the test & train folders into structured data of 600X400 matrix size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_600400 = (600, 400)\n",
    "size_500 = (500, 500)\n",
    "CurrentDir = 'ComputerVision_Udemy/Computer-Vision-with-Python/DATA/chest101/test/NORMAL/'\n",
    "for f in os.listdir('ComputerVision_Udemy/Computer-Vision-with-Python/DATA/chest101/test/NORMAL/'):\n",
    "#for f in os.listdir('.'):\n",
    "    if f.endswith('.jpeg'):\n",
    "        filename = (CurrentDir+f)\n",
    "        #i = Image.open(filename)\n",
    "        img = cv2.imread(filename)\n",
    "        fn, fext = os.path.splitext(f)\n",
    "        #fext = '.png'\n",
    "#         i.thumbnail(size_300)\n",
    "#         i.save('300/{}_300{}'.format(fn, fext))\n",
    "        \n",
    "        #i.thumbnail(size_500)\n",
    "        resized = cv2.resize(img,size_600400)\n",
    "\n",
    "        cv2.imwrite(('demo/600/test/NORMAL/{}_600400{}'.format(fn,fext)),resized)\n",
    "        #print(fn+fext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a For loop to iterate over all pictures within NORMAL, PNEUMONIA folders\n",
    " (1) Read in single file using Pillow library, Image.open(xxx.jpg)\n",
    " (2) Convert into array i.e. asarray(xxx.jpg)\n",
    " (3) that array file go thru .flatten() to get row vector\n",
    " (4) Store that row vector into a file with a new folder \"flatten\"\n",
    " (5) These flatten file will be in array format, *they are not images*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
